[
  {
    "objectID": "notebooks/data_exploration.html#questions",
    "href": "notebooks/data_exploration.html#questions",
    "title": "2  GDPR Fines Data Exploration",
    "section": "2.1 Questions",
    "text": "2.1 Questions\nThrough visualisation the following questions will be explored. This is with the goal of understanding: The financial penalty (fine amount), poor data controllers, particular articles.\nOn the Fine Amount: \n\nHow are the fine amounts distributed?\nHow does the distribution of fine amount change over time?\n\nOn the Controllers: \n\nWho pays the most?\nWho pays the most often?\n\nOn the Articles: \n\nWhich articles are referrenced the most often\n\n\n2.1.1 Fine Value\n\nHow are the fines distributed?\n\n\nCode\ndef big_currency(x, pos):\n    \"\"\"Lots of big amounts paid in fines. (&gt; 1 billion sometimes)\"\"\"\n    if x &gt;= 1e9:\n        return '{:1.1f}B €'.format(x*1e-9)\n    if x &gt;= 1e6:\n        return '{:1.0f}M €'.format(x*1e-6)\n    \n    return '{:1.0f} €'.format(x)\n\n\n\n\nCode\nfig, ax = plt.subplots()\n\nsns.histplot(\n    fines_nozero, x=\"price\",\n    edgecolor=\"white\", linewidth=.5, facecolor=\"midnightblue\",\n    log_scale=True, binrange=(0, 10), bins=20,\n    ax=ax\n)\nfor bar in ax.patches:\n    bar.set_alpha(0.70) \n\nax.set(xlabel= None, ylabel=None)\nax.xaxis.set_major_formatter(big_currency)\n\nfig.supylabel(t=\"GDPR Violations\")\nfig.supxlabel(t=\"GDPR Fine (Euro)\")\n\nfig.canvas.draw()\n\nfig.suptitle(\n    t=\"GDPR Fine Distributions (Log Scale)\", \n    x=ax.get_position().x0,\n    y=ax.get_position().y1,\n    ha=\"left\", fontsize=16,\n)\n\nfig.patch.set_linewidth(1)\nfig.patch.set_edgecolor(\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\nBy visualising the distribution of fines as a simple histogram it was immediately clear there was a large degree of right-skew. This is typical with financial data. Because of the high right-skew, the decision was made to visualise the data on a logarithmic scale.\nTable 2.3 shows the five figure summary of the price column. Fine value ranges from 28 to 1200000000.\nMost of the fines fall between 1000 and 100000 Euros.\n\n\nHow has the distribution of fines changed over time?\nLooking at each year’s distribution of fines as a boxplot allows for them to be compared. If they boxes move up the y-axis it would give credence that the fine values are increasing over time.\nBy including the actual data points (each fine occurence) as an overlayed jitters, it’s also possible to see if the number of fines is increasing.\n\n\nCode\ndf = (fines_nozero.assign(\n    year = lambda x: x.date.dt.year\n))\n\n# make data more friendly for matplotlib\nprices_each_year = df.groupby('year')['price'].apply(lambda x: x.values)\n\n# Get the years as labels\nlabels = list(prices_each_year.keys())\nlabels.sort()\n\n#create a figure with subplots\nfig, ax = plt.subplots(1, 2,\n                       gridspec_kw={'width_ratios': [1, 7]},\n                       sharey=True)\n\n# Create a boxplot for the year 1970\nbox1 = ax[0].boxplot(\n    prices_each_year[1970],\n    labels=['1970'], widths=0.4, showfliers=False,\n    medianprops={'color':'black', 'linewidth':2}\n    )\nax[0].set_ylabel(None)\n\n\n# Create a boxplot for the years other than 1970\nyears_other_than_1970 = [year for year in labels if year != 1970]\nbox2 = ax[1].boxplot(\n    [prices_each_year[year] for year in years_other_than_1970],\n    labels=years_other_than_1970, showfliers=False, widths=0.4,\n    medianprops={'color':'black', 'linewidth':2}\n    )\n\n# smaller caps\nfor box in list((box1, box2)):\n    for cap in box['caps']:\n        cap.set_xdata(cap.get_xdata() - [-0.05, 0.05])\n\nax[1].set_ylabel(None)\n\njittered_x = np.random.normal(0 + 1, 0.1, len(prices_each_year[1970]))\nax[0].scatter(jittered_x, prices_each_year[1970], alpha=0.05, color='midnightblue', s=10)\n\n\n# Overlay the data points for the years other than 1970\nfor i, year in enumerate(years_other_than_1970):\n    jittered_x = np.random.normal(i + 1, 0.1, len(prices_each_year[year]))\n    ax[1].scatter(jittered_x, prices_each_year[year], alpha=0.05, color='midnightblue', s=10)\n\n# delineate the year jump\nax[1].spines.left.set_visible(True)\nax[1].set_yscale('log')\nax[1].yaxis.set_major_formatter(big_currency)\n\n# draw the figure to apply constrained_layout (req for positioning suptitle)\nfig.canvas.draw()\n\nfig.supylabel(\"Price [Log Distribution]\")\nfig.suptitle(\n    t=\"How has the distribution of fines changed over time?\", \n    ha='left',\n    x=ax[0].get_position().x0+0.03,\n    fontsize=16,\n    y=ax[0].get_position().y1*1.015,\n    va='top'\n)\n\n# subtitle\nplt.figtext(x=ax[0].get_position().x0+0.03, y=ax[0].get_position().y1*0.925, s=\"GDPR Fine Distributions Over Time (Log Scale)\", va=\"bottom\", ha=\"left\", size=12)\n\nfig.patch.set_linewidth(1)\nfig.patch.set_edgecolor(\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\nThe plot shows an immediate curiosity: several fines are labelled as being given in 1970. It looks like this was this data’s way of encoding NA for the date of fine.\nThe other boxes only vary slightly. They all show Q1 above 1000, Q2 (median around 10000) and Q3 between 10000 and 100000. One notable exception is 2022 which is lower on the y axis.\nLooking at the number of data points per year it looks like 2022 had more GDPR fines than any other year.\nThis report was conducted late in 2023. While this may explain why there are fewer points on the 2023 box, it still looks like there will be fewer fines than in previous years.\nIt doesn’t look as if there is a clear trend in the distribution of fines.\n\n\n\n2.1.2 Controllers\n\nWho pays the most?\nWho pays the most often?\n\nSome data wrangling is required to create a summary view for each controller. Ideally for each separate controller it would be good to construct a table with:\n\nthe controller name\nthe number of times that controller has been fined\nthe sum of the fines that controller has had to pay\nthe mean of the fines that controller has had to pay\n\nThis is useful for direct comparison.\nThe large companies (e.g. Meta, Amazon) often have multiple different controller names. For simplicity in communication these have been combined (i.e. Meta/Facebook refers to any controller regarding Meta/Facebook: Meta Platforms Inc. (Facebook), Meta Platforms Ireland Limited (Facebook), etc.)\n\nWho pays the most?\n\n\nCode\ndef strfind(series, term):\n    \"\"\"\"\n    time-saver\n    \"\"\"\n    return series.str.contains(term, case=False)\n\n# Give multi-national corps standard names\n# Facebook/Meta Ireland -&gt; Facebook/Meta\nfines_controller_gb = (\n    fines_nozero\n    .assign(\n        shortname = lambda x: np.select(\n            [strfind(x.controller, \"Facebook\"), strfind(x.controller, \"Meta \"), strfind(x.controller, \"Amazon\"),\n             strfind(x.controller, \"Google\"), strfind(x.controller, \"Microsoft\"), strfind(x.controller, \"Vodafone\"),\n             strfind(x.controller, \"WhatsApp\"), strfind(x.controller, \"Clearview\"), strfind(x.controller, \"H&M\"),\n             strfind(x.controller, \"Marriott\")],\n            [\"Facebook/Meta\", \"Facebook/Meta\", \"Amazon\",\n             \"Google\", \"Microsoft\", \"Vodafone\",\n             \"WhatsApp\", \"Clearview AI\", \"H&M\",\n             \"Marriot\"],\n            x.controller\n        )\n    )\n    .assign(shortname = lambda x: x.shortname.str.title().str.strip().replace(\"\"))\n    .groupby('shortname')\n)\n\ncontroller_counts = fines_controller_gb.size().to_frame(name='counts')\ncontroller_stats = (\n    controller_counts\n    .join(fines_controller_gb.agg({'price':'sum'}).rename(columns={'price':'total_price'}))\n    .join(fines_controller_gb.agg({'price':'mean'}).rename(columns={'price':'mean_price'}))\n    .reset_index()\n)\n\ncontroller_stats.sort_values('total_price', ascending=False).head(3)\n\n\n\n\n\n\n\n\n\nshortname\ncounts\ntotal_price\nmean_price\n\n\n\n\n409\nFacebook/Meta\n7\n2337051000\n3.338644e+08\n\n\n47\nAmazon\n3\n748020000\n2.493400e+08\n\n\n1091\nWhatsapp\n2\n230500000\n1.152500e+08\n\n\n\n\n\n\n\n\n\nCode\nTOP_N = 10\n\nfig, ax = plt.subplots()\n\nsns.barplot(y='shortname', x='total_price', data=controller_stats.nlargest(TOP_N, columns='total_price'),\n            color='midnightblue', ax=ax, orient='h', alpha=0.8)\n\nax.set(xlabel=\"\\nTotal Amount Paid in Fines\", ylabel=None)\nax.xaxis.set_major_formatter(big_currency)\n\n\nfig.canvas.draw()\nax.set_title(label=f\"Total Amount Paid in Fines Controllers (Top {TOP_N})\", loc=\"left\", ha=\"left\", size=12)\nfig.suptitle(\n    t=\"Who Pays the Most?\", ha='left', fontsize=16,\n    x=ax.get_position().x0,\n    y=ax.get_position().y1*0.975\n    )\n\nfig.patch.set_linewidth(1)\nfig.patch.set_edgecolor(\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nWho Pays the Most Often?\n\n\nCode\nDONT_INCLUDE = [\"Private Individual\", \"Unknown\", \"Company\", \"Unknown Company\", \"Not Available\"]\n\nfig, ax = plt.subplots()\n\nsns.barplot(y='shortname', x='counts',\n            data=controller_stats.query(f'~shortname.isin({DONT_INCLUDE})').nlargest(n=TOP_N, columns='counts'),\n            color='midnightblue', ax=ax, orient='h', alpha=0.8)\n\nax.set(\n    xlabel=\"\\nn Times Fined\", ylabel=None,\n    xticks=range(0, controller_stats.counts.max(), 10)\n    )\n\nfig.canvas.draw()\n\n# title and subtitle\nax.set_title(\n    label=f\"Number of Times Each Controller has been Fined (Top {TOP_N})\", loc=\"left\", ha=\"left\", size=12)\nfig.suptitle(\n    t=\"Who Pays the Most Often?\", ha='left', fontsize=16,\n    x=ax.get_position().x0,\n    y=ax.get_position().y1*0.975\n    )\n\nfig.patch.set_linewidth(1)\nfig.patch.set_edgecolor(\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.3 Article References\nAt present the data is structured such that each row represents a single instance of an entity being fined in violation of one or more GDPR articles. It’s possible for a single fine to be in reference to multiple articles being violated. To look at specific article violations (i.e. one row per article violation) the data will need to elongated.\n\n\nCode\nfines_long = pivot_fines_longer(fines_nozero)\n\n\n\nWhich articles are referenced the most often?\n\n\nCode\n# df showing article next to how often it was referenced.\nn_citations = (\n    fines_long\n    .value_counts('article_number')\n    .reset_index(name='count')\n    .sort_values('article_number')\n)\n\n\n\n\nCode\nMIN_OCCURENCES = 30\n\nfig, ax = plt.subplots()\n\nsns.barplot(x='article_number', y='count', data=n_citations.query(f'count &gt;= {MIN_OCCURENCES}'), orient='v', color='grey', ax=ax)\nax.tick_params(axis='y', which='major')\nax.set(\n    xlabel='\\nArticle Number',\n    ylabel='Number of Associated Violations/Fines\\n'\n    )\n\nfig.canvas.draw()\n\n# title + subtitle\nax.set_title(f'At least than {MIN_OCCURENCES} instances', loc='left', fontsize=12)\nfig.suptitle('Number of Fines by Article Number', x=ax.get_position().x0, ha='left', fontsize=16, y=ax.get_position().y1*0.975)\n\nfig.patch.set_linewidth(1)\nfig.patch.set_edgecolor(\"black\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\nMIN_OCCURENCES = 30\n\ndf = n_citations.query(f'count &gt;= {MIN_OCCURENCES}').merge(fines_long, how='inner', left_on='article_number', right_on='article_number')\n\nfig, ax = plt.subplots()\n\nsns.stripplot(\n    x='article_number', y='total_fine_euro', data=df,\n    color='black', jitter=0.15, size=3.5, alpha=0.05,\n    ax=ax, zorder=1\n)\n\nsns.boxplot(\n    x='article_number', y='total_fine_euro', data=df,\n    ax=ax,\n    showfliers=False,\n    boxprops={'facecolor':'none'}\n)\n\nax.set_yscale(\"log\")\nax.set(xlabel=\"\\nArticle Number\", ylabel=\"Total Fine (€) [Logarithmic Scale]\\n\")\nax.yaxis.set_major_formatter(big_currency)\n\nfig.canvas.draw()\n\n# title + subtitle\nax.set_title(f'At least than {MIN_OCCURENCES} instances', loc='left', fontsize=12)\nfig.suptitle('Distribution of Total Fine per Article\\'s inclusion', x=ax.get_position().x0, ha='left', fontsize=16, y=ax.get_position().ymax*0.975)\n\nax.grid(visible=True, axis=\"both\")\n\nfig.patch.set_linewidth(1)\nfig.patch.set_edgecolor(\"black\")\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>GDPR Fines Data Exploration</span>"
    ]
  },
  {
    "objectID": "dev.html",
    "href": "dev.html",
    "title": "3  Regression Analysis",
    "section": "",
    "text": "4 TODO:: return to -&gt; decide to delete\ngdpr_model_data = ( overmin_incidence .assign(violated=1, year = lambda x: x.date.dt.year, total_fine_euro = lambda x: np.log10(x.total_fine_euro)) .loc[:, [‘id’,‘year’, ‘country’, ‘total_fine_euro’, ‘article_number’, ‘violated’]] .query(‘year &gt; 2000’) .pivot_table(values=[‘violated’], index=[‘id’, ‘year’, ‘country’, ‘total_fine_euro’, ‘article_number’]) .unstack(level=-1, fill_value=0) )\ngdpr_model_data.columns = gdpr_model_data.columns.droplevel(0) gdpr_model_data.columns.name = None\ngdpr_model_data.columns = [‘A’ + str(col) for col in gdpr_model_data.columns]\ngdpr_model_data = gdpr_model_data.reset_index()\nCode\nimport statsmodels.api as sm\nCode\ngdpr_model_data.describe(include='all').transpose()\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\nid\n1564.0\n833.065217\n489.528139\n1.000000\n408.75000\n821.500000\n1252.250000\n1701.000000\n\n\ntotal_fine_euro\n1564.0\n4.026971\n1.007934\n1.447158\n3.30103\n3.845098\n4.645893\n9.079181\n\n\nyear\n1564.0\n2020.564578\n5.120960\n1970.000000\n2020.00000\n2021.000000\n2022.000000\n2023.000000\n\n\nA2\n1564.0\n0.026854\n0.161709\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA5\n1564.0\n0.527494\n0.499403\n0.000000\n0.00000\n1.000000\n1.000000\n1.000000\n\n\nA6\n1564.0\n0.350384\n0.477243\n0.000000\n0.00000\n0.000000\n1.000000\n1.000000\n\n\nA7\n1564.0\n0.023657\n0.152028\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA9\n1564.0\n0.069054\n0.253627\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA12\n1564.0\n0.111893\n0.315335\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA13\n1564.0\n0.196292\n0.397319\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA14\n1564.0\n0.042199\n0.201108\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA15\n1564.0\n0.069054\n0.253627\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA17\n1564.0\n0.034527\n0.182636\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA21\n1564.0\n0.038363\n0.192133\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA24\n1564.0\n0.028133\n0.165406\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA25\n1564.0\n0.043478\n0.203996\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA28\n1564.0\n0.033887\n0.180997\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA31\n1564.0\n0.021739\n0.145877\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA32\n1564.0\n0.222506\n0.416062\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA33\n1564.0\n0.034527\n0.182636\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA35\n1564.0\n0.023657\n0.152028\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\n\n\nA58\n1564.0\n0.040281\n0.196681\n0.000000\n0.00000\n0.000000\n0.000000\n1.000000\nCode\nX = gdpr_model_data.drop(columns=[\"id\", \"total_fine_euro\"])\ny = gdpr_model_data.total_fine_euro\n\nmod = sm.OLS(y, X.assign(constant=1).astype('float'))\nres = mod.fit()\n\ncoefs = pd.concat([res.params, res.conf_int()], axis=1)\n\ncoefs.columns = ['estimate', 'ci0', 'ci1']\nCode\n# make a nice coeficient table for plotting\ncoefTable = (\n    coefs\n    .reset_index(names='coef')\n    .assign(\n        ci_length = lambda x: x.ci1 - x.estimate,\n        hits0     = lambda x: (0 &gt; x.ci0) & (0 &lt; x.ci1)\n    )\n    .loc[lambda x: x.coef != 'constant', ['coef', 'estimate', 'ci_length', 'hits0']]\n)\nCode\ncoefTable.head(2)\n\n\n\n\n\n\n\n\n\ncoef\nestimate\nci_length\nhits0\n\n\n\n\n0\nyear\n-0.001622\n0.009011\nTrue\n\n\n1\nA2\n-0.456740\n0.297996\nFalse\nCode\ncolors = {'True': 'indianred', 'False': 'steelblue'}\n\nfig, ax = plt.subplots()\n\nax.axhline(y=0, color=\"black\", linestyle=(0, (1, 1)))\nax.set(ylabel=None, xlabel=\"Coefficient Estimate\", title=\"Coefficient Estimates\", xticks=coefTable.index, xticklabels=coefTable.coef)\n\nfor hit_type in np.unique(coefTable.hits0):\n    color = colors[str(hit_type)]\n    df_subset = coefTable.query(f'hits0 == {hit_type}')\n    ax.errorbar(\n        df_subset.index, df_subset.estimate, yerr=df_subset.ci_length,\n        marker='o', color=color, ls='', ms=5, capsize=5, label=hit_type\n    )\n\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regression Analysis</span>"
    ]
  },
  {
    "objectID": "dev.html#creating-a-dataset-for-modelling",
    "href": "dev.html#creating-a-dataset-for-modelling",
    "title": "3  Regression Analysis",
    "section": "3.1 Creating a dataset for Modelling",
    "text": "3.1 Creating a dataset for Modelling\n\n\nCode\n\nMIN_CITATIONS = 30\nINTEREST_VARS = ['year', 'article_number']\n\nindex = ['id', 'total_fine_euro'].extend(INTEREST_VARS)\n\nprint(index)\n\n# pivot data\ngdpr_model_data = (\n    fines\n    .assign(\n        violated=1,\n        total_fine_euro = lambda x: np.log10(x.total_fine_euro),\n        year            = lambda x: x.date.dt.year\n    )\n    .merge(\n        n_citations.query(f'count &gt;= {MIN_CITATIONS}'),\n        how='inner', left_on='article_number', right_on='article_number'\n        )\n    .pivot_table(values=['violated'], index=['id', 'total_fine_euro'] + INTEREST_VARS)\n    .unstack(level=-1, fill_value=0)\n)\n\n# sort out indexing\ngdpr_model_data.columns = gdpr_model_data.columns.droplevel(0)\ngdpr_model_data.columns.name = None\n\ngdpr_model_data.columns = ['A' + str(col) for col in gdpr_model_data.columns]\n\ngdpr_model_data = pd.get_dummies(gdpr_model_data.reset_index())\n\n\nNone\n\n\n\n\nCode\ngdpr_model_data\n\n\n\n\n\n\n\n\n\nid\ntotal_fine_euro\nyear\nA2\nA5\nA6\nA7\nA9\nA12\nA13\n...\nA17\nA21\nA24\nA25\nA28\nA31\nA32\nA33\nA35\nA58\n\n\n\n\n0\n1\n3.972203\n2019\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n\n\n1\n2\n3.397940\n2019\n0\n1\n1\n0\n0\n1\n1\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n3\n4.778151\n2019\n0\n1\n1\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n4\n3.903090\n2019\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n\n\n4\n5\n5.176091\n2019\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n1559\n1696\n4.095169\n2022\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n1560\n1698\n3.301030\n2020\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n1561\n1699\n3.397940\n2020\n0\n1\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n\n\n1562\n1700\n4.301030\n2020\n0\n0\n0\n0\n0\n0\n1\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1563\n1701\n3.602060\n2020\n0\n0\n0\n0\n0\n0\n1\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n1564 rows × 22 columns",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regression Analysis</span>"
    ]
  },
  {
    "objectID": "dev.html#creating-a-dataset-for-modelling-1",
    "href": "dev.html#creating-a-dataset-for-modelling-1",
    "title": "3  Regression Analysis",
    "section": "3.2 Creating a Dataset for Modelling",
    "text": "3.2 Creating a Dataset for Modelling",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Regression Analysis</span>"
    ]
  }
]