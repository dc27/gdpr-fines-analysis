---
title: GDPR Fines Data Exploration
---

This report was produced in Nov 2023 and focusses on exploratory analysis of GDPR penalties. GDPR [(General Data Protection Regulation)](https://gdpr-info.eu/), which aims to protect the information of European Union citizens, took affect in May 2018.

## Setup

```{python}
#| tags: []
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib as mpl
import seaborn as sns

# grab functions from script files. we're in a subdirectory so...
import sys
sys.path.append(r"../")

# helper functions
from scripts.wrangling_funs import filter_for_positives, strip_text_col, pivot_fines_longer

# plot styles
import params.plt_params
```


## Data

The data for this report is scraped from: [Privacy Affairs: GDPR Fines List](https://www.privacyaffairs.com/gdpr-fines/). The  data is then transformed into a tabular format and writtedn to `data/scraped_gdpr_fines.csv` This can be recreated by running:

```python
python scripts/scrape_gdpr_fines.py
```

```{python}
fines = pd.read_csv("../data/scraped_fines.csv", parse_dates=["date"])
```

The data consists of `{python} fines.shape[0]` rows of `{python} fines.shape[1]` variables. Each row of data relates to a single occurence of GDPR violation along with it's penalty amount (fine), the local controller, the organisation found in violation, and the articles of GDPR they were found in violation of.

```{python}
#| label: tbl-data-info-cols
#| tbl-cap: "GDPR Fines: Informative Columns"

with pd.option_context("display.precision", 2):
    display(
        fines
        .drop(columns="id")
        .describe(include=[object])
        .transpose()
        )
```

```{python}
#| label: tbl-data-price-col
#| tbl-cap: "GDPR Fines: Price Column Distribution"

with pd.option_context("display.precision", 2):
    display(
        fines
        .drop(columns='id')
        .describe()
        .transpose()
        )
```

The minumum value of fines is 0. This seems incorrect (and worth investigating!) but with the assumption that fines should fall in the range $ 0 \gt \textrm{fine amount} \gt \inf $. Before performing analysis a minor amount of cleaning is required for the 'raw' data

1. remove fines with 0 price
1. remove whitespace from type column

```{python}
fines_nozero = (
    fines
    .pipe(filter_for_positives, "price")
    .pipe(strip_text_col, "type")
)
```

After cleaning the data there are now `{python} fines_nozero.shape[0]` rows of `{python} fines_nozero.shape[1]` variables.

```{python}
#| label: tbl-data-price-col2
#| tbl-cap: "GDPR Fines: Price Column Distribution"

with pd.option_context("display.precision", 2):
    display(
        fines_nozero
        .drop(columns='id')
        .describe()
        .transpose()
        )
```

# Questions

Through visualisation the following questions will be explored. This is with the goal of understanding: The financial penalty (fine amount), poor data controllers, particular articles.

__On the Fine Amount: __

1. How are the fine amounts distributed?
1. How does the distribution of fine amount change over time?

__On the Controllers: __

1. Who pays the most?
1. Who pays the most often? 

__On the Articles: __

1. Which articles are referrenced the most often

## Fine Value

### How are the fines distributed?

```{python}
def big_currency(x, pos):
    """Lots of big amounts paid in fines. (> 1 billion sometimes)"""
    if x >= 1e9:
        return '{:1.1f}B €'.format(x*1e-9)
    if x >= 1e6:
        return '{:1.0f}M €'.format(x*1e-6)
    
    return '{:1.0f} €'.format(x)
```

```{python}
fig, ax = plt.subplots()

sns.histplot(
    fines_nozero, x="price",
    edgecolor="white", linewidth=.5, facecolor="midnightblue",
    log_scale=True, binrange=(0, 10), bins=20,
    ax=ax
)
for bar in ax.patches:
    bar.set_alpha(0.70) 

ax.set(xlabel= None, ylabel=None)
ax.xaxis.set_major_formatter(big_currency)

fig.supylabel(t="GDPR Violations")
fig.supxlabel(t="GDPR Fine (Euro)")

fig.canvas.draw()

fig.suptitle(
    t="GDPR Fine Distributions (Log Scale)", 
    x=ax.get_position().x0,
    y=ax.get_position().y1,
    ha="left", fontsize=16,
)

fig.patch.set_linewidth(1)
fig.patch.set_edgecolor("black")
plt.show()
```

By visualising the distribution of fines as a simple histogram it was immediately clear there was a large degree of right-skew. This is typical with financial data. Because of the high right-skew, the decision was made to visualise the data on a logarithmic scale.

@tbl-data-price-col2 shows the five figure summary of the price column. Fine value ranges from `{python} fines_nozero.price.min()` to `{python} fines_nozero.price.max()`.

Most of the fines fall between 1000 and 100000 Euros.

### How has the distribution of fines changed over time?

Looking at each year's distribution of fines as a boxplot allows for them to be compared. If they boxes move up the y-axis it would give credence that the fine values are increasing over time.

By including the actual data points (each fine occurence) as an overlayed jitters, it's also possible to see if the number of fines is increasing.

```{python}
#| tags: []
df = (fines_nozero.assign(
    year = lambda x: x.date.dt.year
))

# make data more friendly for matplotlib
prices_each_year = df.groupby('year')['price'].apply(lambda x: x.values)

# Get the years as labels
labels = list(prices_each_year.keys())
labels.sort()

#create a figure with subplots
fig, ax = plt.subplots(1, 2,
                       gridspec_kw={'width_ratios': [1, 7]},
                       sharey=True)

# Create a boxplot for the year 1970
box1 = ax[0].boxplot(
    prices_each_year[1970],
    labels=['1970'], widths=0.4, showfliers=False,
    medianprops={'color':'black', 'linewidth':2}
    )
ax[0].set_ylabel(None)


# Create a boxplot for the years other than 1970
years_other_than_1970 = [year for year in labels if year != 1970]
box2 = ax[1].boxplot(
    [prices_each_year[year] for year in years_other_than_1970],
    labels=years_other_than_1970, showfliers=False, widths=0.4,
    medianprops={'color':'black', 'linewidth':2}
    )

# smaller caps
for box in list((box1, box2)):
    for cap in box['caps']:
        cap.set_xdata(cap.get_xdata() - [-0.05, 0.05])

ax[1].set_ylabel(None)

jittered_x = np.random.normal(0 + 1, 0.1, len(prices_each_year[1970]))
ax[0].scatter(jittered_x, prices_each_year[1970], alpha=0.05, color='midnightblue', s=10)


# Overlay the data points for the years other than 1970
for i, year in enumerate(years_other_than_1970):
    jittered_x = np.random.normal(i + 1, 0.1, len(prices_each_year[year]))
    ax[1].scatter(jittered_x, prices_each_year[year], alpha=0.05, color='midnightblue', s=10)

# delineate the year jump
ax[1].spines.left.set_visible(True)
ax[1].set_yscale('log')
ax[1].yaxis.set_major_formatter(big_currency)

# draw the figure to apply constrained_layout (req for positioning suptitle)
fig.canvas.draw()

fig.supylabel("Price [Log Distribution]")
fig.suptitle(
    t="How has the distribution of fines changed over time?", 
    ha='left',
    x=ax[0].get_position().x0+0.03,
    fontsize=16,
    y=ax[0].get_position().y1*1.015,
    va='top'
)

# subtitle
plt.figtext(x=ax[0].get_position().x0+0.03, y=ax[0].get_position().y1*0.925, s="GDPR Fine Distributions Over Time (Log Scale)", va="bottom", ha="left", size=12)

fig.patch.set_linewidth(1)
fig.patch.set_edgecolor("black")
plt.show()
```


The plot shows an immediate curiosity: several fines are labelled as being given in 1970. It looks like this was this data's way of encoding `NA` for the date of fine.

The other boxes only vary slightly. They all show Q1 above 1000, Q2 (median around 10000) and Q3 between 10000 and 100000. One notable exception is 2022 which is lower on the y axis.

Looking at the number of data points per year it looks like 2022 had more GDPR fines than any other year.

This report was conducted late in 2023. While this may explain why there are fewer points on the 2023 box, it still looks like there will be fewer fines than in previous years.

It doesn't look as if there is a clear trend in the distribution of fines.


## Controllers

1. Who pays the most?
2. Who pays the most often? 

Some data wrangling is required to create a summary view for each controller. Ideally for each separate controller it would be good to construct a table with:

- the controller name
- the number of times that controller has been fined
- the sum of the fines that controller has had to pay
- the mean of the fines that controller has had to pay

This is useful for direct comparison.

The large companies (e.g. Meta, Amazon) often have multiple different controller names. For simplicity in communication these have been combined (i.e. Meta/Facebook refers to any controller regarding Meta/Facebook: Meta Platforms Inc. (Facebook), Meta Platforms Ireland Limited (Facebook), etc.)


### Who pays the most?

```{python}
#| tags: []
def strfind(series, term):
    """"
    time-saver
    """
    return series.str.contains(term, case=False)

# Give multi-national corps standard names
# Facebook/Meta Ireland -> Facebook/Meta
fines_controller_gb = (
    fines_nozero
    .assign(
        shortname = lambda x: np.select(
            [strfind(x.controller, "Facebook"), strfind(x.controller, "Meta "), strfind(x.controller, "Amazon"),
             strfind(x.controller, "Google"), strfind(x.controller, "Microsoft"), strfind(x.controller, "Vodafone"),
             strfind(x.controller, "WhatsApp"), strfind(x.controller, "Clearview"), strfind(x.controller, "H&M"),
             strfind(x.controller, "Marriott")],
            ["Facebook/Meta", "Facebook/Meta", "Amazon",
             "Google", "Microsoft", "Vodafone",
             "WhatsApp", "Clearview AI", "H&M",
             "Marriot"],
            x.controller
        )
    )
    .assign(shortname = lambda x: x.shortname.str.title().str.strip().replace(""))
    .groupby('shortname')
)

controller_counts = fines_controller_gb.size().to_frame(name='counts')
controller_stats = (
    controller_counts
    .join(fines_controller_gb.agg({'price':'sum'}).rename(columns={'price':'total_price'}))
    .join(fines_controller_gb.agg({'price':'mean'}).rename(columns={'price':'mean_price'}))
    .reset_index()
)

controller_stats.sort_values('total_price', ascending=False).head(3)
```

```{python}
#| tags: []
TOP_N = 10

fig, ax = plt.subplots()

sns.barplot(y='shortname', x='total_price', data=controller_stats.nlargest(TOP_N, columns='total_price'),
            color='midnightblue', ax=ax, orient='h', alpha=0.8)

ax.set(xlabel="\nTotal Amount Paid in Fines", ylabel=None)
ax.xaxis.set_major_formatter(big_currency)


fig.canvas.draw()
ax.set_title(label=f"Total Amount Paid in Fines Controllers (Top {TOP_N})", loc="left", ha="left", size=12)
fig.suptitle(
    t="Who Pays the Most?", ha='left', fontsize=16,
    x=ax.get_position().x0,
    y=ax.get_position().y1*0.975
    )

fig.patch.set_linewidth(1)
fig.patch.set_edgecolor("black")
plt.show()
```

### Who Pays the Most Often?

```{python}
#| tags: []


DONT_INCLUDE = ["Private Individual", "Unknown", "Company", "Unknown Company", "Not Available"]

fig, ax = plt.subplots()

sns.barplot(y='shortname', x='counts',
            data=controller_stats.query(f'~shortname.isin({DONT_INCLUDE})').nlargest(n=TOP_N, columns='counts'),
            color='midnightblue', ax=ax, orient='h', alpha=0.8)

ax.set(
    xlabel="\nn Times Fined", ylabel=None,
    xticks=range(0, controller_stats.counts.max(), 10)
    )

fig.canvas.draw()

# title and subtitle
ax.set_title(
    label=f"Number of Times Each Controller has been Fined (Top {TOP_N})", loc="left", ha="left", size=12)
fig.suptitle(
    t="Who Pays the Most Often?", ha='left', fontsize=16,
    x=ax.get_position().x0,
    y=ax.get_position().y1*0.975
    )

fig.patch.set_linewidth(1)
fig.patch.set_edgecolor("black")
plt.show()
```

## Article References

At present the data is structured such that each row represents a single instance of an entity being fined in violation of one or more GDPR articles. It's possible for a single fine to be in reference to multiple articles being violated. To look at specific article violations (i.e. one row per article violation) the data will need to elongated.

```{python}
fines_long = pivot_fines_longer(fines_nozero)
```

### Which articles are referenced the most often?

```{python}
#| tags: []
# df showing article next to how often it was referenced.
n_citations = (
    fines_long
    .value_counts('article_number')
    .reset_index(name='count')
    .sort_values('article_number')
)
```

```{python}
#| tags: []


MIN_OCCURENCES = 30

fig, ax = plt.subplots()

sns.barplot(x='article_number', y='count', data=n_citations.query(f'count >= {MIN_OCCURENCES}'), orient='v', color='grey', ax=ax)
ax.tick_params(axis='y', which='major')
ax.set(
    xlabel='\nArticle Number',
    ylabel='Number of Associated Violations/Fines\n'
    )

fig.canvas.draw()

# title + subtitle
ax.set_title(f'At least than {MIN_OCCURENCES} instances', loc='left', fontsize=12)
fig.suptitle('Number of Fines by Article Number', x=ax.get_position().x0, ha='left', fontsize=16, y=ax.get_position().y1*0.975)

fig.patch.set_linewidth(1)
fig.patch.set_edgecolor("black")
plt.show()
```

```{python}
MIN_OCCURENCES = 30

df = n_citations.query(f'count >= {MIN_OCCURENCES}').merge(fines_long, how='inner', left_on='article_number', right_on='article_number')

fig, ax = plt.subplots()

sns.stripplot(
    x='article_number', y='total_fine_euro', data=df,
    color='black', jitter=0.15, size=3.5, alpha=0.05,
    ax=ax, zorder=1
)

sns.boxplot(
    x='article_number', y='total_fine_euro', data=df,
    ax=ax,
    showfliers=False,
    boxprops={'facecolor':'none'}
)

ax.set_yscale("log")
ax.set(xlabel="\nArticle Number", ylabel="Total Fine (€) [Logarithmic Scale]\n")
ax.yaxis.set_major_formatter(big_currency)

fig.canvas.draw()

# title + subtitle
ax.set_title(f'At least than {MIN_OCCURENCES} instances', loc='left', fontsize=12)
fig.suptitle('Distribution of Total Fine per Article\'s inclusion', x=ax.get_position().x0, ha='left', fontsize=16, y=ax.get_position().ymax*0.975)

ax.grid(visible=True, axis="both")

fig.patch.set_linewidth(1)
fig.patch.set_edgecolor("black")
plt.show()
```
